{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip insall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\amita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Training - lyrics + melody (.mid files with notes, instruments, etc.)\n",
    "# Test - generate lyrics for melody"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: ./\n"
     ]
    }
   ],
   "source": [
    "# Get midi files folder and train/test .csv files\n",
    "def download_and_extract(repo_url, output_path):\n",
    "    # check if the output path exists\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # download ZIP file\n",
    "    response = requests.get(repo_url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract from ZIP file\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "            zip_ref.extractall(output_path)\n",
    "        print(f\"Files extracted to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download ZIP file: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "repo_url = \"https://github.com/Or-Gindes/DeepLearningBGU/raw/main/assignment3/Archive.zip?raw=true\"  # link to the ZIP file\n",
    "output_path = \"./\"  # output directory\n",
    "\n",
    "download_and_extract(repo_url, output_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing MIDIs into vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "  \"\"\"\n",
    "  Dataset object for MIDI files.\n",
    "  Attributes:\n",
    "    dataset: pandas dataframe with columns: artist, title, lyricsx\n",
    "    path_to_mids: path to folder with MIDI files\n",
    "  \"\"\"\n",
    "  def __init__(self, path_to_mids: str, dataset: pd.DataFrame):\n",
    "    self.dataset = dataset.copy()\n",
    "    self.parse_dataset(path_to_mids)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.dataset.iloc[idx, :]\n",
    "\n",
    "  def __getattr__(self, name):\n",
    "      if name in self.dataset.columns:\n",
    "          return self.dataset[name]\n",
    "      raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
    "\n",
    "  def get_item_from_artist_song_name(self, artist, song_name):\n",
    "    \"\"\"\n",
    "    returns item from dataset based on artist and song name\n",
    "    :param artist: artist name\n",
    "    :param song_name: song name\n",
    "    \"\"\"\n",
    "    return self.dataset.loc[self.dataset['artist'] == artist and self.dataset['title'] == song_name, :]\n",
    "\n",
    "  def parse_dataset(self, path_to_mids):\n",
    "    \"\"\"\n",
    "    Parses dataset and adds:\n",
    "      directory column - which contains path to MIDI file.\n",
    "      parsed_mid column - which contains parsed MIDI data.\n",
    "    \"\"\"\n",
    "    self.dataset['directory'] = (path_to_mids + self.dataset.iloc[:, 0].str.strip() + \"_-_\" + self.dataset.iloc[:, 1].str.strip()).str.strip().str.replace(' ', '_') + \".mid\"\n",
    "    files = []\n",
    "    for file in os.listdir(path_to_mids):\n",
    "      if file.endswith('.mid'):\n",
    "        files.append(os.path.join(path_to_mids, file))\n",
    "    cleaned_file_names = [re.sub(r'_-_live.*|_-_extended.*|_-_violin.*|-2.mid', '.mid', file.lower()) for file in files]\n",
    "\n",
    "    directory_dict = dict(zip(cleaned_file_names, files))\n",
    "    self.dataset['directory'] = [directory_dict.get(song) for song in self.dataset['directory']]\n",
    "    self.dataset['parsed_mid'] = self.dataset['directory'].map(MIDIDataset.get_midi_data)\n",
    "    self.dataset = self.dataset.dropna()\n",
    "    self.dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  @staticmethod\n",
    "  def get_midi_data(path_to_mid: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a path extract features from MIDI file\n",
    "    :param path_to_mid: path to MIDI file\n",
    "    :param start_time: start time in seconds from the begining of the song\n",
    "    :param end_time: end time in seconds from the begining of the song\n",
    "    :return:\n",
    "    \"\"\"\n",
    "      # Load MIDI file, handling potential KeySignatureErrors\n",
    "    try:\n",
    "      midi_data = pretty_midi.PrettyMIDI(path_to_mid)\n",
    "    except Exception as e:\n",
    "      print(f\"Skipping file {path_to_mid}: {e}\")\n",
    "      return None  # or handle the error differently as needed\n",
    "\n",
    "    # remove noise\n",
    "    midi_data.remove_invalid_notes()\n",
    "\n",
    "    # parse midi to df\n",
    "    instrument_col = []\n",
    "    pitch_col = []\n",
    "    velocity_col = []\n",
    "    start_col = []\n",
    "    end_col = []\n",
    "    for i, instrument in enumerate(midi_data.instruments):\n",
    "      for j, note in enumerate(instrument.notes):\n",
    "        start_col.append(note.start)\n",
    "        end_col.append(note.end)\n",
    "        instrument_col.append(MIDIDataset.parse_instrument(instrument.name))\n",
    "        pitch_col.append(note.pitch)\n",
    "        velocity_col.append(note.velocity)\n",
    "\n",
    "    end_col = np.array(end_col)\n",
    "    start_col = np.array(start_col)/np.max(end_col)\n",
    "    end_col /= np.max(end_col)\n",
    "    pitch_col = np.array(pitch_col)/127\n",
    "    velocity_col = np.array(velocity_col)/127\n",
    "\n",
    "    df = pd.DataFrame({\"start\": start_col,\n",
    "                      \"end\": end_col,\n",
    "                      \"instrument\": instrument_col,\n",
    "                      \"duration\": end_col - start_col,\n",
    "                      \"pitch\": pitch_col,\n",
    "                      \"velocity\": velocity_col\n",
    "                      })\n",
    "\n",
    "    df = df.sort_values(by=[\"start\", \"end\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    ohe = OneHotEncoder(categories=[['guitar', 'strings', 'keyboard', 'horns', 'drums', 'melody', 'other']])\n",
    "    ohe_columns = ohe.fit_transform(df[[\"instrument\"]])\n",
    "    df.drop(columns=['instrument'], inplace=True)\n",
    "    df = np.concatenate((df.values, ohe_columns.toarray()), axis=1)\n",
    "    return df\n",
    "\n",
    "  @staticmethod\n",
    "  def parse_instrument(instrument):\n",
    "    if re.search(r'guitar|bass', instrument.lower()):\n",
    "      return 'guitar'\n",
    "    elif re.search(r'violin|cello', instrument.lower()):\n",
    "      return 'strings'\n",
    "    elif re.search(r'piano|keyboard|organ', instrument.lower()):\n",
    "      return 'keyboard'\n",
    "    elif re.search(r'sax|saxophone|trump.*|clarinet|flute', instrument.lower()):\n",
    "      return 'horns'\n",
    "    elif re.search(r'drum.*', instrument.lower()):\n",
    "      return 'drums'\n",
    "    elif re.search(r'melody', instrument.lower()):\n",
    "      return 'melody'\n",
    "    else:\n",
    "      return 'other'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amita\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m train \u001B[38;5;241m=\u001B[39m train[\u001B[38;5;241m~\u001B[39mtrain\u001B[38;5;241m.\u001B[39martist\u001B[38;5;241m.\u001B[39misin(unique_artists[random_choice])]\n\u001B[0;32m     17\u001B[0m train\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 19\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[43mMIDIDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./midi_files/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m validation \u001B[38;5;241m=\u001B[39m MIDIDataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./midi_files/\u001B[39m\u001B[38;5;124m\"\u001B[39m, validation)\n\u001B[0;32m     22\u001B[0m test \u001B[38;5;241m=\u001B[39m load_lyrics(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlyrics_test_set.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[13], line 10\u001B[0m, in \u001B[0;36mMIDIDataset.__init__\u001B[1;34m(self, path_to_mids, dataset)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, path_to_mids: \u001B[38;5;28mstr\u001B[39m, dataset: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[0;32m      9\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 10\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_to_mids\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[13], line 46\u001B[0m, in \u001B[0;36mMIDIDataset.parse_dataset\u001B[1;34m(self, path_to_mids)\u001B[0m\n\u001B[0;32m     44\u001B[0m directory_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(cleaned_file_names, files))\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdirectory\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [directory_dict\u001B[38;5;241m.\u001B[39mget(song) \u001B[38;5;28;01mfor\u001B[39;00m song \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdirectory\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m---> 46\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparsed_mid\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdirectory\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMIDIDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_midi_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pandas\\core\\series.py:4700\u001B[0m, in \u001B[0;36mSeries.map\u001B[1;34m(self, arg, na_action)\u001B[0m\n\u001B[0;32m   4620\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmap\u001B[39m(\n\u001B[0;32m   4621\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4622\u001B[0m     arg: Callable \u001B[38;5;241m|\u001B[39m Mapping \u001B[38;5;241m|\u001B[39m Series,\n\u001B[0;32m   4623\u001B[0m     na_action: Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   4624\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series:\n\u001B[0;32m   4625\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4626\u001B[0m \u001B[38;5;124;03m    Map values of Series according to an input mapping or function.\u001B[39;00m\n\u001B[0;32m   4627\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4698\u001B[0m \u001B[38;5;124;03m    dtype: object\u001B[39;00m\n\u001B[0;32m   4699\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4700\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4701\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_values, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39m__finalize__(\n\u001B[0;32m   4702\u001B[0m         \u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmap\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4703\u001B[0m     )\n",
      "File \u001B[1;32m~\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[13], line 61\u001B[0m, in \u001B[0;36mMIDIDataset.get_midi_data\u001B[1;34m(path_to_mid)\u001B[0m\n\u001B[0;32m     59\u001B[0m   \u001B[38;5;66;03m# Load MIDI file, handling potential KeySignatureErrors\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 61\u001B[0m   midi_data \u001B[38;5;241m=\u001B[39m \u001B[43mpretty_midi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPrettyMIDI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_to_mid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSkipping file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_to_mid\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pretty_midi\\pretty_midi.py:107\u001B[0m, in \u001B[0;36mPrettyMIDI.__init__\u001B[1;34m(self, midi_file, resolution, initial_tempo)\u001B[0m\n\u001B[0;32m    100\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    101\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTempo, Key or Time signature change events found on \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    102\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero tracks.  This is not a valid type 0 or type 1 \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    103\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMIDI file.  Tempo, Key or Time Signature may be wrong.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    104\u001B[0m             \u001B[38;5;167;01mRuntimeWarning\u001B[39;00m)\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;66;03m# Populate the list of instruments\u001B[39;00m\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_instruments\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmidi_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresolution \u001B[38;5;241m=\u001B[39m resolution\n",
      "File \u001B[1;32m~\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pretty_midi\\pretty_midi.py:338\u001B[0m, in \u001B[0;36mPrettyMIDI._load_instruments\u001B[1;34m(self, midi_data)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m event\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnote_on\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m event\u001B[38;5;241m.\u001B[39mvelocity \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;66;03m# Store this as the last note-on location\u001B[39;00m\n\u001B[0;32m    337\u001B[0m     note_on_index \u001B[38;5;241m=\u001B[39m (event\u001B[38;5;241m.\u001B[39mchannel, event\u001B[38;5;241m.\u001B[39mnote)\n\u001B[1;32m--> 338\u001B[0m     last_note_on[note_on_index]\u001B[38;5;241m.\u001B[39mappend((\n\u001B[0;32m    339\u001B[0m         event\u001B[38;5;241m.\u001B[39mtime, event\u001B[38;5;241m.\u001B[39mvelocity))\n\u001B[0;32m    340\u001B[0m \u001B[38;5;66;03m# Note offs can also be note on events with 0 velocity\u001B[39;00m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m event\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnote_off\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (event\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnote_on\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    342\u001B[0m                                   event\u001B[38;5;241m.\u001B[39mvelocity \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    343\u001B[0m     \u001B[38;5;66;03m# Check that a note-on exists (ignore spurious note-offs)\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Load train and test lyrics\n",
    "def load_lyrics(path: str) -> pd.DataFrame:\n",
    "  df = pd.read_csv(path, header=None, usecols=[0,1,2])\n",
    "  df.columns = [\"artist\", \"title\", \"lyrics\"]\n",
    "  return df\n",
    "\n",
    "# Load train and test MIDI files, create validation set\n",
    "train = load_lyrics(\"lyrics_train_set.csv\")\n",
    "unique_artists = np.array(list(set(train.artist)))\n",
    "number_of_artists_in_validation = int(len(unique_artists) * 0.1)\n",
    "random_choice = np.random.choice(range(number_of_artists_in_validation), number_of_artists_in_validation, replace=False)\n",
    "\n",
    "validation = train[train.artist.isin(unique_artists[random_choice])]\n",
    "validation.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = train[~train.artist.isin(unique_artists[random_choice])]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = MIDIDataset(\"./midi_files/\", train)\n",
    "validation = MIDIDataset(\"./midi_files/\", validation)\n",
    "\n",
    "test = load_lyrics(\"lyrics_test_set.csv\")\n",
    "test = MIDIDataset(\"./midi_files/\", test)\n",
    "\n",
    "print(\"------------------------------------------\\n-----------------Train:-------------------\\n------------------------------------------\")\n",
    "display(train.dataset.info())\n",
    "print(\"------------------------------------------\\n-----------------Validation:--------------\\n------------------------------------------\")\n",
    "display(validation.dataset.info())\n",
    "print(\"------------------------------------------\\n-----------------Test:--------------------\\n------------------------------------------\")\n",
    "display(test.dataset.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_lyrics(lyrics: pd.Series):\n",
    "  # Maintain line seperation in songs with end-of-line token (eos)\n",
    "  processed_lyrics = lyrics.apply(lambda song: song.replace(\" & \", \" eol \"))\n",
    "\n",
    "  # Remove punctuation\n",
    "  processed_lyrics = processed_lyrics.apply(lambda song: re.sub(r'[^\\w\\s]', '', song))\n",
    "\n",
    "  # Remove numbers\n",
    "  processed_lyrics = processed_lyrics.apply(lambda song: re.sub(r'\\d+', '', song))\n",
    "\n",
    "  # verify all tokens are lower case letters and strip whitespace\n",
    "  # And add end-of-song token (eos)\n",
    "  # Remove cases where 'eol' token appears twice in a row\n",
    "  eol = \"eol\"\n",
    "  pattern = rf'\\b{re.escape(eol)}\\b\\s+\\b{re.escape(eol)}\\b'\n",
    "\n",
    "  tokens = processed_lyrics.apply(lambda lyrics: [\n",
    "      word.lower() for word in re.sub(pattern, eol, lyrics).strip().split()\n",
    "  ] + [\"eos\"])\n",
    "\n",
    "  return tokens\n",
    "\n",
    "tokens = tokenize_lyrics(train.dataset[\"lyrics\"])\n",
    "song_word_count = tokens.apply(len)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(song_word_count)\n",
    "quantile_line = song_word_count.quantile(0.9)\n",
    "plt.plot([quantile_line, quantile_line], [0, 300], ':',\n",
    "         label=f\"90% of songs # Words < {round(quantile_line)}\")\n",
    "plt.xlabel(\"# Words\")\n",
    "plt.ylabel(\"# Songs\")\n",
    "plt.title(\"Number of words for songs in training data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip insall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\amita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Training - lyrics + melody (.mid files with notes, instruments, etc.)\n",
    "# Test - generate lyrics for melody"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: ./\n"
     ]
    }
   ],
   "source": [
    "# Get midi files folder and train/test .csv files\n",
    "def download_and_extract(repo_url, output_path):\n",
    "    # check if the output path exists\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # download ZIP file\n",
    "    response = requests.get(repo_url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract from ZIP file\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "            zip_ref.extractall(output_path)\n",
    "        print(f\"Files extracted to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download ZIP file: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "repo_url = \"https://github.com/Or-Gindes/DeepLearningBGU/raw/main/assignment3/Archive.zip?raw=true\"  # link to the ZIP file\n",
    "output_path = \"./\"  # output directory\n",
    "\n",
    "download_and_extract(repo_url, output_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing MIDIs into vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "  \"\"\"\n",
    "  Dataset object for MIDI files.\n",
    "  Attributes:\n",
    "    dataset: pandas dataframe with columns: artist, title, lyricsx\n",
    "    path_to_mids: path to folder with MIDI files\n",
    "  \"\"\"\n",
    "  def __init__(self, path_to_mids: str, dataset: pd.DataFrame):\n",
    "    self.dataset = dataset.copy()\n",
    "    self.parse_dataset(path_to_mids)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.dataset.iloc[idx, :]\n",
    "\n",
    "  def __getattr__(self, name):\n",
    "      if name in self.dataset.columns:\n",
    "          return self.dataset[name]\n",
    "      raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
    "\n",
    "  def get_item_from_artist_song_name(self, artist, song_name):\n",
    "    \"\"\"\n",
    "    returns item from dataset based on artist and song name\n",
    "    :param artist: artist name\n",
    "    :param song_name: song name\n",
    "    \"\"\"\n",
    "    return self.dataset.loc[self.dataset['artist'] == artist and self.dataset['title'] == song_name, :]\n",
    "\n",
    "  def parse_dataset(self, path_to_mids):\n",
    "    \"\"\"\n",
    "    Parses dataset and adds:\n",
    "      directory column - which contains path to MIDI file.\n",
    "      parsed_mid column - which contains parsed MIDI data.\n",
    "    \"\"\"\n",
    "    self.dataset['directory'] = (path_to_mids + self.dataset.iloc[:, 0].str.strip() + \"_-_\" + self.dataset.iloc[:, 1].str.strip()).str.strip().str.replace(' ', '_') + \".mid\"\n",
    "    files = []\n",
    "    for file in os.listdir(path_to_mids):\n",
    "      if file.endswith('.mid'):\n",
    "        files.append(os.path.join(path_to_mids, file))\n",
    "    cleaned_file_names = [re.sub(r'_-_live.*|_-_extended.*|_-_violin.*|-2.mid', '.mid', file.lower()) for file in files]\n",
    "\n",
    "    directory_dict = dict(zip(cleaned_file_names, files))\n",
    "    self.dataset['directory'] = [directory_dict.get(song) for song in self.dataset['directory']]\n",
    "    self.dataset['parsed_mid'] = self.dataset['directory'].map(MIDIDataset.get_midi_data)\n",
    "    self.dataset = self.dataset.dropna()\n",
    "    self.dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  @staticmethod\n",
    "  def get_midi_data(path_to_mid: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a path extract features from MIDI file\n",
    "    :param path_to_mid: path to MIDI file\n",
    "    :param start_time: start time in seconds from the begining of the song\n",
    "    :param end_time: end time in seconds from the begining of the song\n",
    "    :return:\n",
    "    \"\"\"\n",
    "      # Load MIDI file, handling potential KeySignatureErrors\n",
    "    try:\n",
    "      midi_data = pretty_midi.PrettyMIDI(path_to_mid)\n",
    "    except Exception as e:\n",
    "      print(f\"Skipping file {path_to_mid}: {e}\")\n",
    "      return None  # or handle the error differently as needed\n",
    "\n",
    "    # remove noise\n",
    "    midi_data.remove_invalid_notes()\n",
    "\n",
    "    # parse midi to df\n",
    "    instrument_col = []\n",
    "    pitch_col = []\n",
    "    velocity_col = []\n",
    "    start_col = []\n",
    "    end_col = []\n",
    "    for i, instrument in enumerate(midi_data.instruments):\n",
    "      for j, note in enumerate(instrument.notes):\n",
    "        start_col.append(note.start)\n",
    "        end_col.append(note.end)\n",
    "        instrument_col.append(MIDIDataset.parse_instrument(instrument.name))\n",
    "        pitch_col.append(note.pitch)\n",
    "        velocity_col.append(note.velocity)\n",
    "\n",
    "    end_col = np.array(end_col)\n",
    "    start_col = np.array(start_col)/np.max(end_col)\n",
    "    end_col /= np.max(end_col)\n",
    "    pitch_col = np.array(pitch_col)/127\n",
    "    velocity_col = np.array(velocity_col)/127\n",
    "\n",
    "    df = pd.DataFrame({\"start\": start_col,\n",
    "                      \"end\": end_col,\n",
    "                      \"instrument\": instrument_col,\n",
    "                      \"duration\": end_col - start_col,\n",
    "                      \"pitch\": pitch_col,\n",
    "                      \"velocity\": velocity_col\n",
    "                      })\n",
    "\n",
    "    df = df.sort_values(by=[\"start\", \"end\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    ohe = OneHotEncoder(categories=[['guitar', 'strings', 'keyboard', 'horns', 'drums', 'melody', 'other']])\n",
    "    ohe_columns = ohe.fit_transform(df[[\"instrument\"]])\n",
    "    df.drop(columns=['instrument'], inplace=True)\n",
    "    df = np.concatenate((df.values, ohe_columns.toarray()), axis=1)\n",
    "    return df\n",
    "\n",
    "  @staticmethod\n",
    "  def parse_instrument(instrument):\n",
    "    if re.search(r'guitar|bass', instrument.lower()):\n",
    "      return 'guitar'\n",
    "    elif re.search(r'violin|cello', instrument.lower()):\n",
    "      return 'strings'\n",
    "    elif re.search(r'piano|keyboard|organ', instrument.lower()):\n",
    "      return 'keyboard'\n",
    "    elif re.search(r'sax|saxophone|trump.*|clarinet|flute', instrument.lower()):\n",
    "      return 'horns'\n",
    "    elif re.search(r'drum.*', instrument.lower()):\n",
    "      return 'drums'\n",
    "    elif re.search(r'melody', instrument.lower()):\n",
    "      return 'melody'\n",
    "    else:\n",
    "      return 'other'\n",
    "\n",
    "# Load train and test lyrics\n",
    "def load_lyrics(path: str) -> pd.DataFrame:\n",
    "  df = pd.read_csv(path, header=None, usecols=[0,1,2])\n",
    "  df.columns = [\"artist\", \"title\", \"lyrics\"]\n",
    "  return df\n",
    "\n",
    "# Load train and test MIDI files, create validation set\n",
    "train = load_lyrics(\"lyrics_train_set.csv\")\n",
    "unique_artists = np.array(list(set(train.artist)))\n",
    "number_of_artists_in_validation = int(len(unique_artists) * 0.1)\n",
    "random_choice = np.random.choice(range(number_of_artists_in_validation), number_of_artists_in_validation, replace=False)\n",
    "\n",
    "validation = train[train.artist.isin(unique_artists[random_choice])]\n",
    "validation.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = train[~train.artist.isin(unique_artists[random_choice])]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = MIDIDataset(\"./midi_files/\", train)\n",
    "validation = MIDIDataset(\"./midi_files/\", validation)\n",
    "\n",
    "test = load_lyrics(\"lyrics_test_set.csv\")\n",
    "test = MIDIDataset(\"./midi_files/\", test)\n",
    "\n",
    "print(\"------------------------------------------\\n-----------------Train:-------------------\\n------------------------------------------\")\n",
    "display(train.dataset.info())\n",
    "print(\"------------------------------------------\\n-----------------Validation:--------------\\n------------------------------------------\")\n",
    "display(validation.dataset.info())\n",
    "print(\"------------------------------------------\\n-----------------Test:--------------------\\n------------------------------------------\")\n",
    "display(test.dataset.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_53016\\1587718844.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     19\u001B[0m   ] + [\"eos\"])\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mtokens\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m \u001B[0mtokens\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenize_lyrics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"lyrics\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[0msong_word_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokens\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Downloads\\DeepLearning_EX3\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6295\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6296\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6297\u001B[0m         ):\n\u001B[0;32m   6298\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6299\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "def tokenize_lyrics(lyrics: pd.Series):\n",
    "  # Maintain line seperation in songs with end-of-line token (eos)\n",
    "  processed_lyrics = lyrics.apply(lambda song: song.replace(\" & \", \" eol \"))\n",
    "\n",
    "  # Remove punctuation\n",
    "  processed_lyrics = processed_lyrics.apply(lambda song: re.sub(r'[^\\w\\s]', '', song))\n",
    "\n",
    "  # Remove numbers\n",
    "  processed_lyrics = processed_lyrics.apply(lambda song: re.sub(r'\\d+', '', song))\n",
    "\n",
    "  # verify all tokens are lower case letters and strip whitespace\n",
    "  # And add end-of-song token (eos)\n",
    "  # Remove cases where 'eol' token appears twice in a row\n",
    "  eol = \"eol\"\n",
    "  pattern = rf'\\b{re.escape(eol)}\\b\\s+\\b{re.escape(eol)}\\b'\n",
    "\n",
    "  tokens = processed_lyrics.apply(lambda lyrics: [\n",
    "      word.lower() for word in re.sub(pattern, eol, lyrics).strip().split()\n",
    "  ] + [\"eos\"])\n",
    "\n",
    "  return tokens\n",
    "\n",
    "tokens = tokenize_lyrics(train.dataset[\"lyrics\"])\n",
    "song_word_count = tokens.apply(len)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(song_word_count)\n",
    "quantile_line = song_word_count.quantile(0.9)\n",
    "plt.plot([quantile_line, quantile_line], [0, 300], ':',\n",
    "         label=f\"90% of songs # Words < {round(quantile_line)}\")\n",
    "plt.xlabel(\"# Words\")\n",
    "plt.ylabel(\"# Songs\")\n",
    "plt.title(\"Number of words for songs in training data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
